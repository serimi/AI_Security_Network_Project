{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNC5jmAJpjcitY48ozK6kuT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount(\"/content/MyDrive\")\n","#path of model directory\n","path = \"/content/MyDrive/MyDrive/!\""],"metadata":{"id":"CZG_nGTeILHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yW-OECqbIH-3"},"outputs":[],"source":["# MODEL_process_ver\n","\n","!pip -q install transformers\n","#HuggingFace 사의 BERT 모델 사용해서 임베딩\n","\n","import re\n","from urllib.parse import urlparse\n","#외부 모델 사용하기 위한 라이브러리: transformers&torch\n","from transformers import BertModel, BertTokenizer\n","import torch\n","import numpy as np\n","import pickle\n","\n","\n","def model_process_example(url):\n","    return_types = {\n","        0:('benign', 0.96),\n","        1:('defacement', 0.96),\n","        2:('phishing', 0.84),\n","        3:('malware', 0.94)}\n","    #불필요한 수식어 제거\n","    url = re.sub('www.', '', url)\n","    url = re.sub('http://', '', url)\n","    url = re.sub('https://', '', url)\n","    url = re.sub('.html', '', url)\n","    url = re.sub('.htm', '', url)\n","\n","    #primary url 구하기\n","    reg = re.compile('^(.*?)\\/')\n","    temp = reg.findall(url)\n","    primary_url = '0'\n","    if temp:\n","        primary_url = temp\n","    else:\n","        primary_url = url\n","    #character lengths\n","    num_letters = sum(char.isalpha() for char in url)\n","    num_digits = sum(char.isdigit() for char in url)\n","    special_chars = \"!@#$%^&*()_+-=[]{};:,.<>/?`~|\"\n","    num_special_chars = sum(char in special_chars for char in url)\n","    #shortening service\n","    def has_shortening_ser(url):\n","        pattern = re.compile(r'bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n","                            r'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n","                            r'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n","                            r'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n","                            r'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n","                            r'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n","                            r'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n","                            r'tr\\.im|link\\.zip\\.net')\n","        match = pattern.search(url)\n","        return int(bool(match))\n","    shortening_service = has_shortening_ser(url)\n","    #urls where hostname = domain\n","    def abnormal(url):\n","        parsed_url = urlparse(url)\n","        hostname = parsed_url.hostname\n","        if hostname:\n","            hostname = str(hostname)\n","            match = re.search(hostname, url)\n","            if match:\n","                return 1\n","        return 0\n","    abnormal_url = abnormal(url)\n","    #urls with IP\n","    def have_ip(url):\n","        pattern = r'(([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.' \\\n","                r'([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\/)|' \\\n","                r'(([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.' \\\n","                r'([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\/)|' \\\n","                r'((0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\/)' \\\n","                r'(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}|' \\\n","                r'([0-9]+(?:\\.[0-9]+){3}:[0-9]+)|' \\\n","                r'((?:(?:\\d|[01]?\\d\\d|2[0-4]\\d|25[0-5])\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d|\\d)(?:\\/\\d{1,2})?)'\n","\n","        match = re.search(pattern, url)\n","        if match:\n","            return 1\n","        else:\n","            return 0\n","    is_ip = have_ip(url)\n","\n","    nonbert_features = np.array([len(url), num_letters, num_digits, num_special_chars, shortening_service, abnormal_url, is_ip]).reshape(1,-1)\n","\n","    # Load the pre-trained BERT model and tokenizer\n","    # GPU가 없을 것이기 때문에 CPU사용\n","    model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    # Define a function to extract features for each transaction\n","    def extract_features(text):\n","        # Tokenize the text\n","        input_ids = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)['input_ids']\n","        # Get the hidden states for each token\n","        with torch.no_grad():\n","            outputs = model(input_ids)\n","            hidden_states = outputs[2]\n","        # Concatenate the last 4 hidden states\n","        token_vecs = []\n","        for layer in range(-4, 0):\n","            token_vecs.append(hidden_states[layer][0])\n","        # Calculate the mean of the last 4 hidden states\n","        features = []\n","        for token in token_vecs:\n","            features.append(torch.mean(token, dim=0))\n","        # Return the features as a tensor\n","        return torch.stack(features)\n","    features = extract_features(url).numpy().reshape(1,-1)\n","    dataset = np.hstack((features, nonbert_features))\n","    #path = ' '# 모델 피클이 있을 주소\n","    model_bert = pickle.load(open(path+'model_bert_logreg.pkl', 'rb'))\n","    ans = model_bert.predict(dataset)\n","\n","    return return_types[ans[0]]\n"]},{"cell_type":"markdown","source":["출력 순서대로 예측한 Type, 예측의 정확도 입니다.\n","분류 Type은 데이터셋에서 주어진 대로이며,\n","시연에 사용한 URL은 학습에 사용하지 않은 데이터 중 임의로 선택했습니다."],"metadata":{"id":"__L4VpHeU3kK"}},{"cell_type":"code","source":["# example 1: Benign\n","print(model_process_example('https://www.microsoft.com/ko-kr/windows/?r=1'))"],"metadata":{"id":"HoRJFmMtIfVs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# example 2: Benign\n","print(model_process_example('https://m.blog.naver.com/PostList.naver?blogId=sectoyd&categoryNo=54&logCode=0'))"],"metadata":{"id":"9HsAFHkHI4tZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# example 3: Defacement\n","print(model_process_example('http://www.dedrijfstang.nl/index.php/nieuws'))"],"metadata":{"id":"kN2rFj8YK5Fj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# example 3: Phishing\n","print(model_process_example('signin.eby.de.zukruygxctzmmqi.civpro.co.za'))"],"metadata":{"id":"fW9i0o30K5f5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# example 4: Malware\n","print(model_process_example('http://219.155.221.142:39367/Mozi.m'))"],"metadata":{"id":"Btd0N_39LjgA"},"execution_count":null,"outputs":[]}]}